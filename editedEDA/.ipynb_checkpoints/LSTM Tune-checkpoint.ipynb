{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f615a890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vd/gzksmjq50yj4mhf15m0b04sh0000gn/T/ipykernel_63333/2198534267.py:5: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  from pandas import datetime\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "import matplotlib\n",
    "# be able to save images on server\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79dcbb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mape(y_true, y_pred): \n",
    "    \"\"\"\n",
    "    Compute mean absolute percentage error (MAPE)\n",
    "    \"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2a30b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame a sequence as a supervised learning problem\n",
    "def timeseries_to_supervised(data, lag=1):\n",
    "    df = DataFrame(data)\n",
    "    columns = [df.shift(i) for i in range(1, lag+1)]\n",
    "    columns.append(df)\n",
    "    df = concat(columns, axis=1)\n",
    "    df = df.drop(0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0776c0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a differenced series\n",
    "def difference(dataset, interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "    return Series(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58d82288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "    return yhat + history[-interval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1faf722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale train and test data to [-1, 1]\n",
    "def scale(train, test):\n",
    "    # fit scaler\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler = scaler.fit(train)\n",
    "    # transform train\n",
    "    train = train.reshape(train.shape[0], train.shape[1])\n",
    "    train_scaled = scaler.transform(train)\n",
    "    # transform test\n",
    "    test = test.reshape(test.shape[0], test.shape[1])\n",
    "    test_scaled = scaler.transform(test)\n",
    "    return scaler, train_scaled, test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6cdf8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse scaling for a forecasted value\n",
    "def invert_scale(scaler, X, yhat):\n",
    "    new_row = [x for x in X] + [yhat]\n",
    "    array = numpy.array(new_row)\n",
    "    array = array.reshape(1, len(array))\n",
    "    inverted = scaler.inverse_transform(array)\n",
    "    return inverted[0, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7656c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on a dataset, returns RMSE in transformed units\n",
    "def evaluate(model, raw_data, scaled_dataset, scaler, offset, batch_size):\n",
    "    # separate\n",
    "    X, y = scaled_dataset[:,0:-1], scaled_dataset[:,-1]\n",
    "    # reshape\n",
    "    reshaped = X.reshape(len(X), 1, 1)\n",
    "    # forecast dataset\n",
    "    output = model.predict(reshaped, batch_size=batch_size)\n",
    "    # invert data transforms on forecast\n",
    "    predictions = list()\n",
    "    for i in range(len(output)):\n",
    "        yhat = output[i,0]\n",
    "        # invert scaling\n",
    "        yhat = invert_scale(scaler, X[i], yhat)\n",
    "        # invert differencing\n",
    "        yhat = yhat + raw_data[i]\n",
    "        # store forecast\n",
    "        predictions.append(yhat)\n",
    "    # report performance\n",
    "    rmse = sqrt(mean_squared_error(raw_data[1:], predictions))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43e2859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit an LSTM network to training data\n",
    "def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    for i in range(nb_epoch):\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "        model.reset_states()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5b7ebd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run diagnostic experiments\n",
    "def run(series, epochs):\n",
    "    # transform data to be stationary\n",
    "    raw_values = series['Close'].values\n",
    "    diff_values = difference(raw_values, 1)\n",
    "    # transform data to be supervised learning\n",
    "    supervised = timeseries_to_supervised(diff_values, 1)\n",
    "    supervised_values = supervised.values\n",
    "    # split data into train and test-sets\n",
    "    test_size = 0.2                                                # proportion of dataset to be used as test set\n",
    "    cv_size = 0.2                                                   # proportion of dataset to be used as cross-validation set\n",
    "    num_cv = int(cv_size*len(series))\n",
    "    num_test = int(test_size*len(series))\n",
    "    num_train = len(series) - num_cv - num_test\n",
    "    print(\"num_train = \" + str(num_train))\n",
    "    print(\"num_cv = \" + str(num_cv))\n",
    "    print(\"num_test = \" + str(num_test))\n",
    "    \n",
    "    #train, test = supervised_values[:num_train], supervised_values[-12:]\n",
    "    train = supervised_values[:num_train]\n",
    "    cv = supervised_values[num_train:num_train+num_cv]\n",
    "    train_cv = supervised_values[:num_train+num_cv]\n",
    "    test = supervised_values[num_train+num_cv:]\n",
    "    \n",
    "    # transform the scale of the data\n",
    "    scaler, train_scaled, test_scaled = scale(train, test)\n",
    "#     # fit and evaluate model\n",
    "#     train_trimmed = train_scaled[2:, :]\n",
    "#     # config\n",
    "#     repeats = 5\n",
    "#     n_batch = batch\n",
    "#     n_epochs = epochs\n",
    "#     n_neurons = neurons\n",
    "#     # run diagnostic tests\n",
    "#     for i in range(repeats):\n",
    "#         history = fit_lstm(train_trimmed, test_scaled, raw_values, scaler, n_batch, n_epochs, n_neurons)\n",
    "#         pyplot.plot(history['train'], color='blue')\n",
    "#         pyplot.plot(history['test'], color='orange')\n",
    "#         print('%d) TrainRMSE=%f, TestRMSE=%f' % (i, history['train'].iloc[-1], history['test'].iloc[-1]))\n",
    "#     pyplot.savefig('epochs_diagnostic.png')\n",
    "\n",
    "    # run experiment\n",
    "    error_scores = list()\n",
    "    for r in range(5): # repeat 5 times\n",
    "        # fit the model\n",
    "        batch_size = 2\n",
    "        train_trimmed = train_scaled[2:, :]\n",
    "        lstm_model = fit_lstm(train_trimmed, batch_size, epochs, 1)\n",
    "        # forecast the entire training dataset to build up state for forecasting\n",
    "        train_reshaped = train_trimmed[:, 0].reshape(len(train_trimmed), 1, 1)\n",
    "        lstm_model.predict(train_reshaped, batch_size=batch_size)\n",
    "        # forecast test dataset\n",
    "        test_reshaped = test_scaled[:,0:-1]\n",
    "        test_reshaped = test_reshaped.reshape(len(test_reshaped), 1, 1)\n",
    "        output = lstm_model.predict(test_reshaped, batch_size=batch_size)\n",
    "        predictions = list()\n",
    "        for i in range(len(output)):\n",
    "            yhat = output[i,0]\n",
    "            X = test_scaled[i, 0:-1]\n",
    "            # invert scaling\n",
    "            yhat = invert_scale(scaler, X, yhat)\n",
    "            # invert differencing\n",
    "            yhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "            # store forecast\n",
    "            predictions.append(yhat)\n",
    "        # report performance\n",
    "        # print(len(predictions))\n",
    "        rmse = sqrt(mean_squared_error(raw_values[num_train+num_cv+2:], predictions))\n",
    "        print('%d) Test RMSE: %.3f' % (r+1, rmse))\n",
    "        error_scores.append(rmse)\n",
    "    return error_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c667eaea",
   "metadata": {},
   "source": [
    "# Tuning the Number of Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d03bfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train = 438\n",
      "num_cv = 146\n",
      "num_test = 146\n",
      "1) Test RMSE: 1703.747\n",
      "2) Test RMSE: 1702.548\n",
      "3) Test RMSE: 1702.533\n",
      "4) Test RMSE: 1705.193\n",
      "5) Test RMSE: 1704.416\n",
      "num_train = 438\n",
      "num_cv = 146\n",
      "num_test = 146\n",
      "1) Test RMSE: 1719.411\n",
      "2) Test RMSE: 1718.971\n",
      "3) Test RMSE: 1718.890\n",
      "4) Test RMSE: 1711.849\n",
      "5) Test RMSE: 1719.525\n",
      "num_train = 438\n",
      "num_cv = 146\n",
      "num_test = 146\n",
      "1) Test RMSE: 1719.326\n",
      "2) Test RMSE: 1720.551\n",
      "3) Test RMSE: 1718.219\n",
      "4) Test RMSE: 1702.538\n",
      "5) Test RMSE: 1702.538\n",
      "               100          500         1000\n",
      "count     5.000000     5.000000     5.000000\n",
      "mean   1703.687542  1717.729271  1712.634508\n",
      "std       1.165236     3.298373     9.253619\n",
      "min    1702.533243  1711.849267  1702.537997\n",
      "25%    1702.548222  1718.889873  1702.537999\n",
      "50%    1703.747220  1718.970958  1718.219465\n",
      "75%    1704.416033  1719.410791  1719.326435\n",
      "max    1705.192992  1719.525465  1720.550643\n"
     ]
    }
   ],
   "source": [
    "series = read_csv('../data/dataset.csv', header=0, parse_dates=[0], index_col=0, squeeze=True)\n",
    "# experiment\n",
    "results = DataFrame()\n",
    "# vary training epochs\n",
    "epochs = [100, 500, 1000]\n",
    "for e in epochs:\n",
    "    results[str(e)] = run(series, e)\n",
    "# summarize results\n",
    "print(results.describe())\n",
    "# save boxplot\n",
    "results.boxplot()\n",
    "pyplot.savefig('boxplot_epochs.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c98c839",
   "metadata": {},
   "source": [
    "# Tuning the Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "66ee8020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run diagnostic experiments\n",
    "def run(series, batch_size):\n",
    "    # transform data to be stationary\n",
    "    raw_values = series['Close'].values\n",
    "    diff_values = difference(raw_values, 1)\n",
    "    # transform data to be supervised learning\n",
    "    supervised = timeseries_to_supervised(diff_values, 1)\n",
    "    supervised_values = supervised.values\n",
    "    # split data into train and test-sets\n",
    "    test_size = 0.2                                                # proportion of dataset to be used as test set\n",
    "    cv_size = 0.2                                                   # proportion of dataset to be used as cross-validation set\n",
    "    num_cv = int(cv_size*len(series))\n",
    "    num_test = int(test_size*len(series))\n",
    "    num_train = len(series) - num_cv - num_test\n",
    "    print(\"num_train = \" + str(num_train))\n",
    "    print(\"num_cv = \" + str(num_cv))\n",
    "    print(\"num_test = \" + str(num_test))\n",
    "    \n",
    "    #train, test = supervised_values[:num_train], supervised_values[-12:]\n",
    "    train = supervised_values[:num_train]\n",
    "    cv = supervised_values[num_train:num_train+num_cv]\n",
    "    train_cv = supervised_values[:num_train+num_cv]\n",
    "    test = supervised_values[num_train+num_cv:]\n",
    "    \n",
    "    # transform the scale of the data\n",
    "    scaler, train_scaled, test_scaled = scale(train, test)\n",
    "    \n",
    "    # run experiment\n",
    "    error_scores = list()\n",
    "    for r in range(5): # repeat 5 times\n",
    "        # fit the model\n",
    "        epochs = 100\n",
    "        train_trimmed = train_scaled[2:, :]\n",
    "        lstm_model = fit_lstm(train_trimmed, batch_size, epochs, 1)\n",
    "        # forecast the entire training dataset to build up state for forecasting\n",
    "        train_reshaped = train_trimmed[:, 0].reshape(len(train_trimmed), 1, 1)\n",
    "        lstm_model.predict(train_reshaped, batch_size=batch_size)\n",
    "        # forecast test dataset\n",
    "        test_reshaped = test_scaled[:,0:-1]\n",
    "        test_reshaped = test_reshaped.reshape(len(test_reshaped), 1, 1)\n",
    "        output = lstm_model.predict(test_reshaped, batch_size=batch_size)\n",
    "        predictions = list()\n",
    "        for i in range(len(output)):\n",
    "            yhat = output[i,0]\n",
    "            X = test_scaled[i, 0:-1]\n",
    "            # invert scaling\n",
    "            yhat = invert_scale(scaler, X, yhat)\n",
    "            # invert differencing\n",
    "            yhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "            # store forecast\n",
    "            predictions.append(yhat)\n",
    "        # report performance\n",
    "        # print(len(predictions))\n",
    "        rmse = sqrt(mean_squared_error(raw_values[num_train+num_cv+2:], predictions))\n",
    "        print('%d) Test RMSE: %.3f' % (r+1, rmse))\n",
    "        # Calculate MAPE\n",
    "        mape = get_mape(raw_values[num_train+num_cv+2:], predictions)\n",
    "        print('%d) Test MAPE: %.3f' % mape)\n",
    "        error_scores.append(rmse)\n",
    "    return error_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9fc0b54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train = 438\n",
      "num_cv = 146\n",
      "num_test = 146\n",
      "1) Test RMSE: 1701.655\n",
      "2) Test RMSE: 1704.484\n",
      "3) Test RMSE: 1709.741\n",
      "4) Test RMSE: 1701.651\n",
      "5) Test RMSE: 1701.653\n",
      "num_train = 438\n",
      "num_cv = 146\n",
      "num_test = 146\n",
      "1) Test RMSE: 1702.543\n",
      "2) Test RMSE: 1704.679\n",
      "3) Test RMSE: 1707.922\n",
      "4) Test RMSE: 1702.548\n",
      "5) Test RMSE: 1709.524\n",
      "num_train = 438\n",
      "num_cv = 146\n",
      "num_test = 146\n",
      "1) Test RMSE: 1700.624\n",
      "2) Test RMSE: 1709.342\n",
      "3) Test RMSE: 1703.242\n",
      "4) Test RMSE: 1706.924\n",
      "5) Test RMSE: 1710.377\n",
      "                 1            2            4\n",
      "count     5.000000     5.000000     5.000000\n",
      "mean   1703.836946  1705.443145  1706.101425\n",
      "std       3.521020     3.169207     4.112080\n",
      "min    1701.650832  1702.543104  1700.623546\n",
      "25%    1701.653166  1702.547774  1703.241787\n",
      "50%    1701.655222  1704.678801  1706.923559\n",
      "75%    1704.484015  1707.922197  1709.341556\n",
      "max    1709.741496  1709.523851  1710.376676\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "series = read_csv('../data/dataset.csv', header=0, parse_dates=[0], index_col=0, squeeze=True)\n",
    "# experiment\n",
    "results = DataFrame()\n",
    "# vary training batches\n",
    "batches = [1, 2, 4]\n",
    "for b in batches:\n",
    "    results[str(b)] = run(series, b)\n",
    "# summarize results\n",
    "print(results.describe())\n",
    "# save boxplot\n",
    "results.boxplot()\n",
    "pyplot.savefig('boxplot_batches.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b7a819",
   "metadata": {},
   "source": [
    "# Tuning the Number of Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "380a5cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run diagnostic experiments\n",
    "def run(series, neurons):\n",
    "    # transform data to be stationary\n",
    "    raw_values = series['Close'].values\n",
    "    diff_values = difference(raw_values, 1)\n",
    "    # transform data to be supervised learning\n",
    "    supervised = timeseries_to_supervised(diff_values, 1)\n",
    "    supervised_values = supervised.values\n",
    "    # split data into train and test-sets\n",
    "    test_size = 0.2                                                # proportion of dataset to be used as test set\n",
    "    cv_size = 0.2                                                   # proportion of dataset to be used as cross-validation set\n",
    "    num_cv = int(cv_size*len(series))\n",
    "    num_test = int(test_size*len(series))\n",
    "    num_train = len(series) - num_cv - num_test\n",
    "    print(\"num_train = \" + str(num_train))\n",
    "    print(\"num_cv = \" + str(num_cv))\n",
    "    print(\"num_test = \" + str(num_test))\n",
    "    \n",
    "    #train, test = supervised_values[:num_train], supervised_values[-12:]\n",
    "    train = supervised_values[:num_train]\n",
    "    cv = supervised_values[num_train:num_train+num_cv]\n",
    "    train_cv = supervised_values[:num_train+num_cv]\n",
    "    test = supervised_values[num_train+num_cv:]\n",
    "    \n",
    "    # transform the scale of the data\n",
    "    scaler, train_scaled, test_scaled = scale(train, test)\n",
    "    \n",
    "    # run experiment\n",
    "    error_scores = list()\n",
    "    for r in range(5): # repeat 5 times\n",
    "        # fit the model\n",
    "        epochs = 100\n",
    "        batch_size = 1\n",
    "        train_trimmed = train_scaled[2:, :]\n",
    "        lstm_model = fit_lstm(train_trimmed, batch_size, epochs, neurons)\n",
    "        # forecast the entire training dataset to build up state for forecasting\n",
    "        train_reshaped = train_trimmed[:, 0].reshape(len(train_trimmed), 1, 1)\n",
    "        lstm_model.predict(train_reshaped, batch_size=batch_size)\n",
    "        # forecast test dataset\n",
    "        test_reshaped = test_scaled[:,0:-1]\n",
    "        test_reshaped = test_reshaped.reshape(len(test_reshaped), 1, 1)\n",
    "        output = lstm_model.predict(test_reshaped, batch_size=batch_size)\n",
    "        predictions = list()\n",
    "        for i in range(len(output)):\n",
    "            yhat = output[i,0]\n",
    "            X = test_scaled[i, 0:-1]\n",
    "            # invert scaling\n",
    "            yhat = invert_scale(scaler, X, yhat)\n",
    "            # invert differencing\n",
    "            yhat = inverse_difference(raw_values, yhat, len(test_scaled)+1-i)\n",
    "            # store forecast\n",
    "            predictions.append(yhat)\n",
    "        # report performance\n",
    "        # print(len(predictions))\n",
    "        rmse = sqrt(mean_squared_error(raw_values[num_train+num_cv+2:], predictions))\n",
    "        print('%d) Test RMSE: %.3f' % (r+1, rmse))\n",
    "        error_scores.append(rmse)\n",
    "    return error_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b45271b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train = 438\n",
      "num_cv = 146\n",
      "num_test = 146\n",
      "1) Test RMSE: 1701.651\n",
      "2) Test RMSE: 1705.397\n",
      "3) Test RMSE: 1705.758\n",
      "4) Test RMSE: 1701.654\n",
      "5) Test RMSE: 1701.656\n",
      "num_train = 438\n",
      "num_cv = 146\n",
      "num_test = 146\n",
      "1) Test RMSE: 1720.423\n",
      "2) Test RMSE: 1710.231\n",
      "3) Test RMSE: 1701.706\n",
      "4) Test RMSE: 1721.935\n",
      "5) Test RMSE: 1714.259\n",
      "num_train = 438\n",
      "num_cv = 146\n",
      "num_test = 146\n",
      "1) Test RMSE: 1721.752\n",
      "2) Test RMSE: 1718.646\n",
      "3) Test RMSE: 1714.947\n",
      "4) Test RMSE: 1721.116\n",
      "5) Test RMSE: 1722.583\n",
      "num_train = 438\n",
      "num_cv = 146\n",
      "num_test = 146\n",
      "1) Test RMSE: 1721.643\n",
      "2) Test RMSE: 1725.821\n",
      "3) Test RMSE: 1722.500\n",
      "4) Test RMSE: 1712.994\n",
      "5) Test RMSE: 1718.563\n",
      "num_train = 438\n",
      "num_cv = 146\n",
      "num_test = 146\n",
      "1) Test RMSE: 1743.555\n",
      "2) Test RMSE: 1727.691\n",
      "3) Test RMSE: 1736.798\n",
      "4) Test RMSE: 1721.762\n",
      "5) Test RMSE: 1723.559\n",
      "                 1            2            3            4            5\n",
      "count     5.000000     5.000000     5.000000     5.000000     5.000000\n",
      "mean   1703.223307  1713.710852  1719.808973  1720.304392  1730.672848\n",
      "std       2.153012     8.204047     3.089120     4.835379     9.251706\n",
      "min    1701.651073  1701.705938  1714.947227  1712.994228  1721.761955\n",
      "25%    1701.654199  1710.230774  1718.645978  1718.562935  1723.558573\n",
      "50%    1701.655932  1714.259116  1721.116228  1721.642881  1727.690798\n",
      "75%    1705.397180  1720.423185  1721.752210  1722.500440  1736.797882\n",
      "max    1705.758150  1721.935244  1722.583221  1725.821475  1743.555031\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vd/gzksmjq50yj4mhf15m0b04sh0000gn/T/ipykernel_63333/2509329465.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# save boxplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'boxplot_neurons.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36mboxplot_frame\u001b[0;34m(self, column, by, ax, fontsize, rot, grid, figsize, layout, return_type, backend, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m ):\n\u001b[1;32m    510\u001b[0m     \u001b[0mplot_backend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_plot_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m     return plot_backend.boxplot_frame(\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0mcolumn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/plotting/_matplotlib/boxplot.py\u001b[0m in \u001b[0;36mboxplot_frame\u001b[0;34m(self, column, by, ax, fontsize, rot, grid, figsize, layout, return_type, **kwds)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m     ax = boxplot(\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0mcolumn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/plotting/_matplotlib/boxplot.py\u001b[0m in \u001b[0;36mboxplot\u001b[0;34m(data, column, by, ax, fontsize, rot, grid, figsize, layout, return_type, **kwds)\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/plotting/_matplotlib/boxplot.py\u001b[0m in \u001b[0;36mplot_group\u001b[0;34m(keys, values, ax)\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremainder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdivmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                 \u001b[0;32massert\u001b[0m \u001b[0mremainder\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremainder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m                 \u001b[0mkeys\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "series = read_csv('../data/dataset.csv', header=0, parse_dates=[0], index_col=0, squeeze=True)\n",
    "# experiment\n",
    "results = DataFrame()\n",
    "# vary neurons\n",
    "neurons = [1, 2, 3, 4, 5]\n",
    "for n in neurons:\n",
    "    results[str(n)] = run(series, n)\n",
    "# summarize results\n",
    "print(results.describe())\n",
    "# save boxplot\n",
    "results.boxplot()\n",
    "pyplot.savefig('boxplot_neurons.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b06054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data to be stationary\n",
    "raw_values = series['Close'].values\n",
    "diff_values = difference(raw_values, 1)\n",
    "# transform data to be supervised learning\n",
    "supervised = timeseries_to_supervised(diff_values, 1)\n",
    "supervised_values = supervised.values\n",
    "# split data into train and test-sets\n",
    "test_size = 0.2                                                # proportion of dataset to be used as test set\n",
    "cv_size = 0.2                                                   # proportion of dataset to be used as cross-validation set\n",
    "num_cv = int(cv_size*len(series))\n",
    "num_test = int(test_size*len(series))\n",
    "num_train = len(series) - num_cv - num_test\n",
    "print(\"num_train = \" + str(num_train))\n",
    "print(\"num_cv = \" + str(num_cv))\n",
    "print(\"num_test = \" + str(num_test))\n",
    "\n",
    "#train, test = supervised_values[:num_train], supervised_values[-12:]\n",
    "train = supervised_values[:num_train]\n",
    "cv = supervised_values[num_train:num_train+num_cv]\n",
    "train_cv = supervised_values[:num_train+num_cv]\n",
    "test = supervised_values[num_train+num_cv:]\n",
    "\n",
    "# transform the scale of the data\n",
    "scaler, train_scaled, test_scaled = scale(train, test)\n",
    "train_trimmed = train_scaled[2:, :]\n",
    "    \n",
    "lstm_model = fit_lstm(train_trimmed, 1, 100, 1)\n",
    "lstm_model.predict(train_reshaped, batch_size=batch_size)\n",
    "\n",
    "test_reshaped = test_scaled[:,0:-1]\n",
    "test_reshaped = test_reshaped.reshape(len(test_reshaped), 1, 1)\n",
    "output = lstm_model.predict(test_reshaped, batch_size=batch_size)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1381e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
